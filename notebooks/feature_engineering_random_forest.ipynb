{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5732fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TRACK A: COMPETING RANDOM FOREST AGAINST THE XGBOOST CHAMPION ON ORIGINAL DATA ---\n",
      "\n",
      "--- Step 1: Loading and Preparing df_analysis.csv ---\n",
      "✅ Successfully loaded and processed df_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "\n",
    "print(\"--- TRACK A: COMPETING RANDOM FOREST AGAINST THE XGBOOST CHAMPION ON ORIGINAL DATA ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# STEP 1: LOAD AND PREPARE THE ORIGINAL df_analysis.csv DATA\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Step 1: Loading and Preparing df_analysis.csv ---\")\n",
    "try:\n",
    "    # We load the original dataset, not df_historical\n",
    "    df = pd.read_csv('..\\data\\df_analysis.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Year'].astype(str) + '-' + df['Day_of_Year'].astype(str), format='%Y-%j')\n",
    "    df.set_index('Date', inplace=True)\n",
    "    print(\"✅ Successfully loaded and processed df_analysis.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ FATAL ERROR: df_analysis.csv not found.\")\n",
    "    exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d071adc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features to match the Phase 1 Champion model...\n",
      "✅ Data prepared for modeling. This is the same data the XGBoost Champion was trained on.\n",
      "\n",
      "--- Step 2: Tuning Random Forest with RandomizedSearchCV ---\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Best parameters found for Random Forest: {'n_estimators': 100, 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_features': 0.75, 'max_depth': 20, 'bootstrap': True}\n",
      "✅ Final Random Forest model trained.\n",
      "\n",
      "--- Step 3: Evaluating Random Forest Performance ---\n",
      "\n",
      "--- RANDOM FOREST MODEL PERFORMANCE (Challenging the XGBoost Champion) ---\n",
      "Horizon t+1: Max Temp MAE = 1.40°C | Min Temp MAE = 0.96°C\n",
      "Horizon t+1: Max Temp RMSE = 1.98°C | Min Temp RMSE = 1.27°C\n",
      "Horizon t+2: Max Temp MAE = 1.60°C | Min Temp MAE = 1.07°C\n",
      "Horizon t+2: Max Temp RMSE = 2.22°C | Min Temp RMSE = 1.43°C\n",
      "Horizon t+3: Max Temp MAE = 1.68°C | Min Temp MAE = 1.13°C\n",
      "Horizon t+3: Max Temp RMSE = 2.34°C | Min Temp RMSE = 1.51°C\n"
     ]
    }
   ],
   "source": [
    "# This is the full feature engineering from PHASE 1. No RH features are included.\n",
    "print(\"Engineering features to match the Phase 1 Champion model...\")\n",
    "df['Daily_Temp_Range'] = df['Max_Temp_C'] - df['Min_Temp_C']\n",
    "for i in [1, 2, 3, 7]:\n",
    "    for col in ['Max_Temp_C', 'Min_Temp_C', 'Precipitation_mm']:\n",
    "        df[f'{col}_lag_{i}'] = df[col].shift(i)\n",
    "for window in [7, 30]:\n",
    "    for col in ['Max_Temp_C', 'Min_Temp_C']:\n",
    "        df[f'{col}_rolling_mean_{window}d'] = df[col].rolling(window=window).mean()\n",
    "        df[f'{col}_rolling_std_{window}d'] = df[col].rolling(window=window).std()\n",
    "    df[f'Precipitation_mm_rolling_sum_{window}d'] = df['Precipitation_mm'].rolling(window=window).sum()\n",
    "    df[f'Precipitation_mm_rolling_std_{window}d'] = df['Precipitation_mm'].rolling(window=window).std()\n",
    "df['Daily_Temp_Range_lag_1'] = df['Daily_Temp_Range'].shift(1)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Create targets (3-day horizon) and define X, y\n",
    "for h in range(1, 4):\n",
    "    df[f'Target_Max_Temp_C_t+{h}'] = df['Max_Temp_C'].shift(-h)\n",
    "    df[f'Target_Min_Temp_C_t+{h}'] = df['Min_Temp_C'].shift(-h)\n",
    "df.dropna(subset=[f'Target_Max_Temp_C_t+3'], inplace=True)\n",
    "\n",
    "target_cols = [col for col in df.columns if 'Target_' in str(col)]\n",
    "feature_cols = [col for col in df.columns if col not in ['Max_Temp_C', 'Min_Temp_C'] + target_cols]\n",
    "X = df[feature_cols]\n",
    "y = df[target_cols]\n",
    "\n",
    "# Use the same train/test split for a fair comparison\n",
    "split_date = '2020-01-01'\n",
    "X_train, X_test = X[X.index < split_date], X[X.index >= split_date]\n",
    "y_train, y_test = y[y.index < split_date], y[y.index >= split_date]\n",
    "print(\"✅ Data prepared for modeling. This is the same data the XGBoost Champion was trained on.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# STEP 2: TUNE AND TRAIN THE RANDOM FOREST MODEL\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Step 2: Tuning Random Forest with RandomizedSearchCV ---\")\n",
    "# Define a robust parameter grid for Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 250, 400, 500],       # How many trees in the forest\n",
    "    'max_features': [0.5, 0.75, 1.0],           # Number of features to consider at each split\n",
    "    'max_depth': [10, 20, 30, 40, None],        # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10, 15],        # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4, 6],           # Minimum number of samples required at each leaf node\n",
    "    'bootstrap': [True]                         # Always True for Random Forest (sampling with replacement)\n",
    "}\n",
    "\n",
    "# We tune on the primary target (t+1 Max Temp) and then wrap the best model\n",
    "# in MultiOutputRegressor to handle all targets.\n",
    "primary_target_train = y_train['Target_Max_Temp_C_t+1']\n",
    "\n",
    "rf_estimator = RandomForestRegressor(random_state=42, n_jobs=-1, oob_score=True, bootstrap=True)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_estimator,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,  # A reasonable number of iterations for a fair search\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(X_train, primary_target_train)\n",
    "\n",
    "print(f\"\\n✅ Best parameters found for Random Forest: {random_search.best_params_}\")\n",
    "\n",
    "# Create the final multi-output model using the best found parameters\n",
    "final_rf_model = MultiOutputRegressor(\n",
    "    RandomForestRegressor(**random_search.best_params_, random_state=42, n_jobs=-1)\n",
    ")\n",
    "final_rf_model.fit(X_train, y_train)\n",
    "print(\"✅ Final Random Forest model trained.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# STEP 3: EVALUATE THE RANDOM FOREST CHALLENGER\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Step 3: Evaluating Random Forest Performance ---\")\n",
    "rf_predictions = final_rf_model.predict(X_test)\n",
    "rf_pred_df = pd.DataFrame(rf_predictions, index=X_test.index, columns=y_test.columns)\n",
    "\n",
    "print(\"\\n--- RANDOM FOREST MODEL PERFORMANCE (Challenging the XGBoost Champion) ---\")\n",
    "for i in range(1, 4):\n",
    "    mae_max = mean_absolute_error(y_test[f'Target_Max_Temp_C_t+{i}'], rf_pred_df[f'Target_Max_Temp_C_t+{i}'])\n",
    "    rmse_max = root_mean_squared_error(y_test[f'Target_Max_Temp_C_t+{i}'], rf_pred_df[f'Target_Max_Temp_C_t+{i}'])\n",
    "    mae_min = mean_absolute_error(y_test[f'Target_Min_Temp_C_t+{i}'], rf_pred_df[f'Target_Min_Temp_C_t+{i}'])\n",
    "    rmse_min = root_mean_squared_error(y_test[f'Target_Min_Temp_C_t+{i}'], rf_pred_df[f'Target_Min_Temp_C_t+{i}'])\n",
    "    print(f\"Horizon t+{i}: Max Temp MAE = {mae_max:.2f}°C | Min Temp MAE = {mae_min:.2f}°C\")\n",
    "    print(f\"Horizon t+{i}: Max Temp RMSE = {rmse_max:.2f}°C | Min Temp RMSE = {rmse_min:.2f}°C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e194b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
